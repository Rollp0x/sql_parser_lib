use crate::ast::SQLStatement;
use crate::token::{Token,self};
use std::error::Error;
use std::fmt;

pub mod expr;
pub mod common;
pub mod select;
pub mod delete;
pub mod insert;

// è§£æé”™è¯¯
#[derive(Debug)]
pub struct ParseError {
    pub message: String,
    pub token_position: usize,
}

impl fmt::Display for ParseError {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(
            f,
            "Parse error at position {}: {}",
            self.token_position, self.message
        )
    }
}

impl Error for ParseError {}

// æ ¸å¿ƒè§£æå™¨ç»“æ„
pub struct Parser {
    tokens: Vec<Token>,
    current: usize,
}

// è¯­å¥è§£ææ¥å£
pub trait StatementParser {
    // å°†è§£æçš„Tokenæµè½¬æ¢ä¸ºå¯¹åº”çš„è¯­å¥ç±»å‹
    fn parse(&mut self) -> Result<SQLStatement, ParseError>;
}

// æ·»åŠ åŸºæœ¬åŠŸèƒ½
impl Parser {
    pub fn new(tokens: Vec<Token>) -> Self {
        Parser { tokens, current: 0 }
    }
    pub fn new_from_sql(sql: &str) -> Self {
        let tokens = token::tokenize(sql);
        Parser { tokens, current: 0 }
    }

    // ===== è¿­ä»£å™¨é£æ ¼æ–¹æ³• =====

    // è¿”å›å½“å‰tokenä½†ä¸æ¶ˆè´¹å®ƒ
    pub fn peek(&self) -> Option<&Token> {
        self.tokens.get(self.current)
    }

    // è¿”å›å½“å‰tokenä¹‹åçš„ç¬¬nä¸ªtoken
    pub fn peek_n(&self, n: usize) -> Option<&Token> {
        self.tokens.get(self.current + n)
    }

    // æ¶ˆè´¹å½“å‰tokenå¹¶è¿”å›å®ƒ
    pub fn consume_token(&mut self) -> Option<Token> {
        if self.current < self.tokens.len() {
            let token = self.tokens[self.current].clone();
            self.current += 1;
            Some(token)
        } else {
            None
        }
    }

    // æ£€æŸ¥åºåˆ—ä¸­æ˜¯å¦è¿˜æœ‰æ›´å¤štoken
    pub fn has_more(&self) -> bool {
        self.current < self.tokens.len()
    }

    // æ¶ˆè´¹nä¸ªtoken
    pub fn skip(&mut self, n: usize) {
        self.current = std::cmp::min(self.current + n, self.tokens.len());
    }

    // å›é€€ä¸€ä¸ªtoken
    pub fn back(&mut self) {
        if self.current > 0 {
            self.current -= 1;
        }
    }

    // ===== è§£æå™¨ç‰¹å®šæ–¹æ³• =====

    // å°è¯•åŒ¹é…ä¸€ä¸ªæ ‡ç‚¹ç¬¦å·
    pub fn match_punctuator(&mut self, punctuator: char) -> bool {
        if let Some(Token::Punctuator(p)) = self.peek() {
            if *p == punctuator {
                self.consume_token(); // æ¶ˆè´¹åŒ¹é…çš„token
                return true;
            }
        }
        false
    }

    pub fn is_punctuator(&self, punctuator: char) -> bool {
        if let Some(Token::Punctuator(p)) = self.peek() {
            return *p == punctuator;
        }
        false
    }

    // å°è¯•åŒ¹é…ä¸€ä¸ªå…³é”®å­—
    pub fn match_keyword(&mut self, keyword: &str) -> bool {
        if let Some(Token::Keyword(k)) = self.peek() {
            if k.to_uppercase() == keyword.to_uppercase() {
                self.consume_token(); // æ¶ˆè´¹åŒ¹é…çš„token
                return true;
            }
        }
        false
    }

    pub fn is_keyword(&self, keyword: &str) -> bool {
        if let Some(Token::Keyword(k)) = self.peek() {
            return k.to_uppercase() == keyword.to_uppercase();
        }
        false
    }

    // å°è¯•åŒ¹é…ä¸€ä¸ªæ“ä½œç¬¦
    pub fn match_operator(&mut self, operator: &str) -> bool {
        if let Some(Token::Operator(op)) = self.peek() {
            if op == operator {
                self.consume_token(); // æ¶ˆè´¹åŒ¹é…çš„token
                return true;
            }
        }
        false
    }
    pub fn is_operator(&self, operator: &str) -> bool {
        if let Some(Token::Operator(op)) = self.peek() {
            return op == operator;
        }
        false
    }

    // å°†tokenæ ¼å¼åŒ–ä¸ºæ›´å¯è¯»çš„å½¢å¼
    pub fn format_token(&self, token: &Token) -> String {
        match token {
            Token::Keyword(k) => k.clone(),
            Token::Identifier(id) => id.clone(),
            Token::StringLiteral(s) => format!("'{}'", s),
            Token::NumericLiteral(n) => n.to_string(),
            Token::Punctuator(c) => c.to_string(),
            _ => {
                // å…¶ä»–tokenç±»å‹...
                format!("{:?}", token)
            }
        }
    }

    // è¾…åŠ©æ–¹æ³•ï¼šç”Ÿæˆé”™è¯¯ä¸Šä¸‹æ–‡
    pub fn get_error_context(&self) -> String {
        // è·å–å½“å‰ä½ç½®å‰åçš„å‡ ä¸ªtoken
        let start = if self.current > 3 {
            self.current - 3
        } else {
            0
        };
        let end = std::cmp::min(self.current + 2, self.tokens.len());

        // å°†tokensè½¬æ¢ä¸ºå¯è¯»å­—ç¬¦ä¸²
        let context_tokens: Vec<String> = self.tokens[start..end]
            .iter()
            .enumerate()
            .map(|(i, t)| {
                let pos = start + i;
                let marker = if pos == self.current { "ğŸ‘‰ " } else { "" };
                format!("{}{}", marker, self.format_token(t))
            })
            .collect();

        format!("\"{}\"", context_tokens.join(" "))
    }

    pub fn get_parse_error(&self, message: &str) -> ParseError {
        let context = self.get_error_context();
        ParseError {
            message: format!("{}. Near: {}", message, context),
            token_position: self.current,
        }
    }
}
